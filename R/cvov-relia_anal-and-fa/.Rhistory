y <- 3
c(x, y)
x > y
x <- 3
y <- 2
c(x, y)
x > y
x >= y
x < y
x <= y
x != y
x == y
c(x, y)
x + y
x - y
x * y
x / y
x %% y
x <- 5
y <- 3
x %% y
x %/% y
x / y
x + y
x - y
x * y
x / y
x %% y
x %/% y
x + y; x - y; x * y
quit()
x <- 1:10
(x - mean(x))^3
sum(x - mean(x))^3)/length(x)
sum((x - mean(x))^3)/length(x)
x <- round(runif(10, 20, 100))
sum((x - mean(x))^3)/length(x)
sum((x - mean(x))^3)/length(x)/(sum((x - mean(x))^2)/length(x))^(3/2)
install.packages('moments')
library(moments)
skewness(x)
sample(1:6, 10, replace = F)
sample(1:6, 3, replace = F)
sample(1:6, 6, replace = F)
sample(1:6, 5, replace = F)
abstracts <- read.csv(file.choose())
names(abstracts)
length(abstracts)
abstracts <- read.csv(file.choose())
names(abstracts)
length(abstracts)
dim(abstracts)
ab_corp <- VCorpus((VectorSource(t(abstracts))))
library(tm) #load text mining library
ab_corp <- VCorpus((VectorSource(t(abstracts))))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
ab_corp <- VCorpus((VectorSource(abstracts)))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
abstracts_corp <- tm_map(abstracts_corp, content_transformer(tolower))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
head(abstracts)
names(abstracts)
ab_corp <- VCorpus((VectorSource(abstracts[, 'abstract'])))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
ab_corp <- VCorpus((VectorSource(t(abstracts[, 'abstract']))))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
ab_corp <- Corpus(DataframeSource(abstracts[, 'abstracts']))
ab_corp <- Corpus(DataframeSource(abstracts[, 'abstract']))
ab_corp <- Corpus(DataframeSource(abstracts))
names(abstracts)
names(abstracts)
abs <- abstracts[, "abstract"]
length(t(abs))
ab_corp <- VCorpus((VectorSource(t(abs))))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
abstracts_corp <- tm_map(abstracts_corp, content_transformer(tolower))
ab_corp <- VCorpus((VectorSource((abs))))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
abstracts_corp <- tm_map(t(ab_corp), stripWhitespace)
abstracts_corp <- tm_map(abstracts_corp, content_transformer(tolower))
abstracts_corp <- tm_map(abstracts_corp, removeWords, stopwords("english"))
abstracts_corp <- tm_map(abstracts_corp, removeNumbers)
abstracts_corp <- tm_map(abstracts_corp, removePunctuation)
summary(abstracts_corp)
dtm <-DocumentTermMatrix(abstracts_corp)
dim(tm::inspect(im_dtm))
dim(tm::inspect(dtm))
length(t(abs))
ab_corp <- VCorpus((VectorSource(t(abs))))
ab_corp
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
dtm <-DocumentTermMatrix(ab_corp)
dim(tm::inspect(dtm))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
abs <- Corpus(DataframeSource(abstracts))
is.na(abstracts)
abstracts <- read.csv(file.choose())
names(abstracts)
length(t(abs))
is.na(abstracts)
abs <- Corpus(DataframeSource(abstracts))
abs <- abstracts[, "abstract"]
length(t(abs))
length(abs)
ab_corp <- VCorpus((VectorSource(t(abs))))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
ab_corp <- VCorpus((VectorSource(abs)))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
is.na(abstracts)
abs <- Corpus(DataframeSource(abstracts))
abs <- abstracts[, "abstract"]
abs <- Corpus(DataframeSource(abs))
abstracts <- read.csv(file.choose())
names(abstracts)
is.na(abstracts)
abs <- Corpus(DataframeSource(abstracts))
abs <- abstracts[, "abstract"]
abs <- Corpus(DataframeSource(abs))
abs <- tm::Corpus(tm::DataframeSource(abs))
ab_corp <- VCorpus((VectorSource(abs)))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
abs <- abstracts[, "abstract"]
length(abs)
ab_corp <- VCorpus((VectorSource(t(abs))))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
abstracts_corp <- tm_map(t(ab_corp), stripWhitespace)
abstracts_corp <- tm_map(abstracts_corp, content_transformer(tolower))
abstracts_corp <- tm_map(abstracts_corp, removeWords, stopwords("english"))
abstracts_corp <- tm_map(abstracts_corp, removeNumbers)
abstracts_corp <- tm_map(abstracts_corp, removePunctuation)
summary(abstracts_corp)
dtm <-DocumentTermMatrix(ab_corp)
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
install.packages('qdap')
library(qdap)
names(abstracts)
m <- list(ID = "no.", content = "abstract")
myReader <- readTabular(mapping = m)
myReader <- tm::readTabular(mapping = m)
detach('package:qdap')
library(tm) #load text mining library
myReader <- tm::readTabular(mapping = m)
DataframeSource(abs)
DataframeSource(abstracts)
abstracts <- read.csv(file.choose())
DataframeSource(abstracts)
abs <- abstracts[, "abstract"]
class(abs)
length(abs)
abs[1]
ab_corp <- VCorpus((VectorSource(t(abs))))
class(ab_corp)
length(ab_corp)
dtm <-DocumentTermMatrix(ab_corp)
abstracts_corp <- tm_map(abstracts_corp, content_transformer(tolower))
dtm <-DocumentTermMatrix(ab_corp)
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
ab_corp <- VCorpus((VectorSource(abs)))
abstracts_corp <- tm_map(ab_corp, stripWhitespace)
library(qdap)
mycorpus <- with(abstracts, as.Corpus(abstracts, no.))
mycorpus <- as.Corpus(abstracts)
mycorpus <- as.Corpus(abstracts[, 'abstract'])
mycorpus
mydtm <- as.dtm(Filter(as.wfm(mycorpus, stopwords = tm::stopwords("english"))))
mydtm <- as.dtm(Filter(as.wfm(mycorpus,
col1 = "docs", col2 = "text",
stopwords = tm::stopwords("english")), 3, 10))
mycorpus <- as.Corpus(abstracts)
abstracts <- read.csv(file.choose())
mycorpus <- with(df, as.Corpus(txt, doc))
mycorpus <- with(df, as.Corpus(doc, txt))
mycorpus <- with(abstracts, as.Corpus(txt, ID))
mycorpus <- with(abstracts, as.Corpus(txt, doc))
mydtm <- as.dtm(Filter(as.wfm(mycorpus,
col1 = "docs", col2 = "text",
stopwords = tm::stopwords("english")), 3, 10))
abs <- read.csv(file.choose())
tdm <- TermDocumentMatrix(crude,control = list(removePunctuation = TRUE, stopwords = TRUE))
tdm <- TermDocumentMatrix(abs, control = list(removePunctuation = TRUE, stopwords = TRUE))
tm::inspect(tdm)
dtm <- DocumentTermMatrix(abs, control = list(removePunctuation = TRUE, stopwords = TRUE))
tm::inspect(dtm)
dtm <- DocumentTermMatrix(abs[, 'abstract'], control = list(removePunctuation = TRUE, stopwords = TRUE))
dtm <- DocumentTermMatrix(abs[, 'txt'], control = list(removePunctuation = TRUE, stopwords = TRUE))
names(abs)
dtm <- DocumentTermMatrix(abs, control = list(removePunctuation = TRUE, stopwords = TRUE))
tm::inspect(dtm)
inspect(tdm[100:110, 1:9])
tm::inspect(tdm[100:110, 1:9])
dim(dtm)
tdm <- TermDocumentMatrix(abs, control = list(removePunctuation = TRUE, stopwords = TRUE))
tm::inspect(tdm)
abs <- abs[, 'txt']
names(abs)
dtm <- DocumentTermMatrix(abs, control = list(removePunctuation = TRUE, stopwords = TRUE))
abs <- read.csv(file.choose())
names(abs)
dim(abs)
help('crude')
dim(crude)
data(crude)
dim(crude)
class(crude)
corp <- VCorpus(abs[, 'txt'])
corp <- VCorpus(VectorSource(abs[, 'txt']))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
dtm <- DocumentTermMatrix(corp, control = list(removePunctuation = TRUE, stopwords = TRUE))
abs <- read.csv(file.choose())
corp <- VCorpus(VectorSource(abs[, 'txt']))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
tdm <- TermDocumentMatrix(corp, control = list(removePunctuation = TRUE, stopwords = TRUE))
corp <- VCorpus(VectorSource(abs))
tdm <- TermDocumentMatrix(corp, control = list(removePunctuation = TRUE, stopwords = TRUE))
corp <- VCorpus(VectorSource(abs[, 'txt']))
class(corp)
tm::inspect(corp)
abs <- read.csv(file.choose())
corp <- VCorpus(VectorSource(abs[, 'txt']))
class(corp)
tm::inspect(corp)
tdm <- TermDocumentMatrix(corp, control = list(removePunctuation = TRUE, stopwords = TRUE))
abs <- read.csv(file.choose())
names(abs)
txt <- abs["txt"]
length(t(txt))
corp <- VCorpus((VectorSource(t(txt))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
abs <- read.csv(file.choose())
names(abs)
lit <- read.csv(file.choose())
names(lit)
lit_abs <- lit["Abstract"]
length(t(im_abs))
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
tm::inspect(dtm)
lit <- read.csv(file.choose())
names(lit)
length(t(lit_abs))
lit_abs <- lit["Abstract"]
lit_abs <- lit["abstracts"]
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
lit <- read.csv(file.choose())
lit_abs <- lit["Abstract"]
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
tm::inspect(dtm)
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wordcloud(names(freq), freq, min.freq=400, max.words=Inf, random.order=FALSE, colors=brewer.pal(8, "Accent"), scale=c(7,.4), rot.per=0)
library(wordcloud)
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
wordcloud(names(freq), freq, min.freq=400, max.words=Inf, random.order=FALSE, colors=brewer.pal(8, "Accent"), scale=c(7,.4), rot.per=0)
tm::inspect(dtm)
lit <- read.csv(file.choose())
names(lit)
lit_abs <- lit["Abstract"]
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
lit <- read.csv(file.choose())
lit <- read.csv(file.choose())
names(lit)
lit_abs <- lit["Abstract"]
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
tm::inspect(dtm)
length(tm::inspect(dtm))
::inspect(dtm)[101]
tm::inspect(dtm)[101]
dim(tm::inspect(dtm))
tm::inspect(dtm)[1:10, ]
tm::inspect(dtm)[1:5, ]
dim(tm::inspect(dtm))
hcdf <- tm::inspect(dtm)
class(hcdf)
head(hcdf)
class(hcdf)
is.data.frame(hcdf)
hcdf <- data.frame(tm::inspect(dtm))
is.data.frame(hcdf)
head(hcdf)
tdm <- TermDocumentMatrix(corp, control = list(removePunctuation = TRUE, stopwords = TRUE))
dim(tm::inspect(tdm))
lit <- read.csv(file.choose())
names(lit)
lit_abs <- lit["Abstract"]
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
imdf <- data.frame(tm::inspect(dtm))
class(imdf)
head(imdf)
is.data.frame(imdf)
names(hcdf)
names(imdf)
intersect(names(hcdf),
names(imdf))
lit <- read.csv(file.choose())
lit_abs <- lit["Abstract"]
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
lit <- read.csv(file.choose(), encoding = "UTF-8")
lit_abs <- lit["Abstract"]
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
lit <- iconv(lit, "WINDOWS-1252","UTF-8")
names(lit)
lit <- read.csv(file.choose(), encoding = "UTF-8")
iconv(lit, "WINDOWS-1252","UTF-8")
iconv(lit, "WINDOWS-1252","UTF-8")
names(lit)
lit_abs <- lit["Abstract"]
length(t(lit_abs))
corp <- VCorpus((VectorSource(t(lit_abs))))
dtm <- DocumentTermMatrix(corp,
control = list(weighting =
function(x)
weightTfIdf(x, normalize =
FALSE),
stopwords = TRUE))
lit <- read.csv(file.choose(), encoding = "UTF-8")
lit <- as.data.frame(
lapply(lit, enc2utf8),
stringsAsFactors = FALSE
)
lit <- as.data.frame(
lapply(lit, enc2utf8),
)
write.csv(lit, "data_input.csv",  fileEncoding = "UTF-8")
lit <- read.csv(file.choose(), encoding = "UTF-8")
coronadata <- read.csv("D:/Research/papers/covid19/MAIN/data/causeandeffect/hc-covid19-sem-data.csv")
names(coronadata)
coronadatascaled <- scale(coronadata[, 2:14])
View(coronadatascaled)
coronamodel <- '
pandemic =~ Active.Cases + Cured.Discharged.Migrated + Deaths
healthcap =~ NumPrimaryHealthCenters_HMIS + NumCommunityHealthCenters_HMIS + NumSubDistrictHospitals_HMIS + NumDistrictHospitals_HMIS + NumPublicBeds_HMIS + NumRuralHospitals_NHP18 + NumRuralBeds_NHP18 + NumUrbanHospitals_NHP18 + NumUrbanBeds_NHP18
# direct
pandemic =~ c*healthcap
# mediator
Received.all.8.basic.vaccinations ~ a*healthcap
pandemic ~ b*Received.all.8.basic.vaccinations
# indirect effect (a*b)
ab := a*b
# total effect
total := c + (a*b)
'
coronafit <- lavaan::sem(coronamodel, data = coronadatascaled)
coronamodel <- '
pandemic =~ Active.Cases + Cured.Discharged.Migrated + Deaths
healthcap =~ NumPrimaryHealthCenters_HMIS + NumCommunityHealthCenters_HMIS + NumPublicBeds_HMIS + NumRuralHospitals_NHP18 + NumRuralBeds_NHP18 + NumUrbanHospitals_NHP18 + NumUrbanBeds_NHP18
# direct
pandemic =~ c*healthcap
# mediator
Received.all.8.basic.vaccinations ~ a*healthcap
pandemic ~ b*Received.all.8.basic.vaccinations
# indirect effect (a*b)
ab := a*b
# total effect
total := c + (a*b)
'
coronafit <- lavaan::sem(coronamodel, data = coronadatascaled)
coronafit
summary(coronafit, fit.measures= TRUE)
library(semPlot)
library(semptools)
p_pa2 <- semPaths(coronafit, whatLabels = "est",
sizeMan = 10,
edge.label.cex = 1.15,
style = "ram",
nCharNodes = 0, nCharEdges = 0)
par(mfrow=c(1, 2))
semPaths(coronafit)
p_pa3 <- mark_sig(p_pa1, coronafit)
par(mfrow=c(1, 2))
par(mfrow=c(1, 2))
semPaths(coronafit)
p_pa3 <- mark_sig(p_pa1, coronafit)
plot(p_pa3)
p_pa2 <- semPaths(coronafit, whatLabels = "est",
sizeMan = 10,
edge.label.cex = 1.15,
style = "ram",
nCharNodes = 0, nCharEdges = 0)
opencolab <- read.csv(file.choose())
opencolabsc <- scale(opencolab)
cor(opencolabsc)
ocirevdata <- read.csv(file.choose())
cor(ocirevdata, method = 'kendall')
write.csv(cov(ocirevdata), 'covariance.csv')
write.csv(cor(ocirevdata), 'correlation.csv')
heatmap(ocirevdata)
ocirevdata
head(ocirevdata)
is.numeric(ocirevdata)
heatmap(as.matrix(ocirevdata))
library(psych)
omega(ocirevdata)
omega(as.matrix(ocirevdata))
alpha(ocirevdata)
# reliability
rel <- alpha(opencolab)
names(opencolab)
# reliability
rel <- alpha(ocirevdata)
rel
rel$total
getwd()
setwd('D:/Research/papers/HC/oci/outputs/relia_anal')
path
path <- 'D:\Research\papers\HC\oci\outputs\relia_anal'
path
path <- as.character('D:\Research\papers\HC\oci\outputs\relia_anal')
path <- readlines()
path <- readline()
path
path <- gsub('\\\\', '/', path)
path
getwd()
write.csv(rel$total, 'alpha.csv')
rel$alpha.drop
write.csv(rel$alpha.drop, 'alpha-drop.csv')
rel$item.stats
write.csv(rel$item.stats, 'item-stats.csv')
rel$response.freq
rel$scores
fit <- fa(ocirevdata, 1)
structure.diagram(fit)
fit <- fa(as.matrix(ocirevdata), 1)
fit <- fa(complete.cases(ocirevdata), 1)
fit <- factanal(ocirevdata, 1)
fit <- factanal(as.matrix(ocirevdata), 1)
fit1 <- fa(opencolab, 3)
sum(is.na(ocirevdata))
is.na(ocirevdata)
fit <- factanal(scale(ocirevdata), 1)
scale(ocirevdata)
ocirevdatach <- ocirevdata[, c(4, 5, 6, 7, 9, 10)]
ocirevdatach
scale(ocirevdatach)
alpha(ocirevdata)
fit <- factanal(scale(ocirevdatach), 1)
fit <- fa(scale(ocirevdatach), 1)
structure.diagram(fit)
structure.diagram(fit)
fit <- fa(scale(ocirevdatach), 3)
structure.diagram(fit)
fit <- fa(scale(ocirevdatach), 2)
structure.diagram(fit)
write.csv(loadings(fit), 'two-factor-loadings.csv')
write.csv(fit$r.scores, 'two-factor-rscores.csv')
